#!/usr/bin/env python3
"""
å¤§è¦æ¨¡ãƒªãƒ©ãƒƒã‚¯ã‚¹ã‚«ãƒ†ã‚´ãƒªãƒ¼åé›†ã‚·ã‚¹ãƒ†ãƒ 
4ã‚«ãƒ†ã‚´ãƒªãƒ¼ Ã— 100ãƒ‡ãƒ¼ã‚¿ Ã— 7åœ°åŸŸ = 2800ä»¶åé›†
æ°¸ç¶šç”»åƒURLå¯¾å¿œ + APIåˆ¶é™ç®¡ç†
"""

import os
import json
import requests
import time
import mysql.connector
from dotenv import load_dotenv
from datetime import datetime
from utils.request_guard import (
    get_json,
    get_photo_direct_url,
)

load_dotenv()

class MassiveRelaxCollector:
    """å¤§è¦æ¨¡ãƒªãƒ©ãƒƒã‚¯ã‚¹ã‚«ãƒ†ã‚´ãƒªãƒ¼åé›†ã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        self.api_key = os.getenv('GOOGLE_API_KEY')
        self.mysql_config = {
            'host': 'localhost',
            'user': 'Haruto',
            'password': os.getenv('MYSQL_PASSWORD'),
            'database': 'swipe_app_development',
            'charset': 'utf8mb4'
        }

        # åé›†å¯¾è±¡è¨­å®š
        self.categories = {
            'parks': {
                'japanese': 'å…¬åœ’',
                'search_terms': ['å…¬åœ’', 'park', 'ç·‘åœ°', 'åºƒå ´', 'éŠåœ’åœ°']
            },
            'sauna': {
                'japanese': 'ã‚µã‚¦ãƒŠ',
                'search_terms': ['ã‚µã‚¦ãƒŠ', 'sauna', 'ã‚¹ãƒ‘', 'å²©ç›¤æµ´']
            },
            'cafe': {
                'japanese': 'ã‚«ãƒ•ã‚§',
                'search_terms': ['ã‚«ãƒ•ã‚§', 'cafe', 'coffee', 'ã‚³ãƒ¼ãƒ’ãƒ¼']
            },
            'walking_courses': {
                'japanese': 'æ•£æ­©ã‚³ãƒ¼ã‚¹',
                'search_terms': ['æ•£æ­©é“', 'ã‚¦ã‚©ãƒ¼ã‚­ãƒ³ã‚°ã‚³ãƒ¼ã‚¹', 'éŠæ­©é“', 'ãƒ—ãƒ­ãƒ ãƒŠãƒ¼ãƒ‰', 'æ•£ç­–è·¯']
            }
        }

        self.regions = {
            'hokkaido': {
                'name': 'åŒ—æµ·é“',
                'cities': ['æœ­å¹Œ', 'å‡½é¤¨', 'æ—­å·', 'å¸¯åºƒ', 'é‡§è·¯', 'åŒ—è¦‹', 'å°æ¨½']
            },
            'tohoku': {
                'name': 'æ±åŒ—',
                'cities': ['ä»™å°', 'é’æ£®', 'ç››å²¡', 'ç§‹ç”°', 'å±±å½¢', 'ç¦å³¶', 'éƒ¡å±±']
            },
            'kanto': {
                'name': 'é–¢æ±',
                'cities': ['æ±äº¬', 'æ¨ªæµœ', 'åŸ¼ç‰', 'åƒè‘‰', 'èŒ¨åŸ', 'æ ƒæœ¨', 'ç¾¤é¦¬']
            },
            'chubu': {
                'name': 'ä¸­éƒ¨',
                'cities': ['åå¤å±‹', 'é™å²¡', 'æ–°æ½Ÿ', 'å¯Œå±±', 'é‡‘æ²¢', 'ç¦äº•', 'å±±æ¢¨', 'é•·é‡', 'å²é˜œ']
            },
            'kansai': {
                'name': 'é–¢è¥¿',
                'cities': ['å¤§é˜ª', 'äº¬éƒ½', 'ç¥æˆ¸', 'å¥ˆè‰¯', 'å’Œæ­Œå±±', 'æ»‹è³€']
            },
            'chugoku_shikoku': {
                'name': 'ä¸­å›½ãƒ»å››å›½',
                'cities': ['åºƒå³¶', 'å²¡å±±', 'å±±å£', 'é³¥å–', 'å³¶æ ¹', 'é«˜æ¾', 'æ¾å±±', 'é«˜çŸ¥', 'å¾³å³¶']
            },
            'kyushu_okinawa': {
                'name': 'ä¹å·ãƒ»æ²–ç¸„',
                'cities': ['ç¦å²¡', 'åŒ—ä¹å·', 'ç†Šæœ¬', 'é¹¿å…å³¶', 'é•·å´', 'å¤§åˆ†', 'å®®å´', 'ä½è³€', 'é‚£è¦‡']
            }
        }

        self.api_usage = 0
        self.collected_spots = 0

    def search_places(self, query, region, city, category_key):
        """Google Places APIã§å ´æ‰€ã‚’æ¤œç´¢"""
        if not self.api_key:
            return []

        try:
            url = "https://maps.googleapis.com/maps/api/place/textsearch/json"
            full_query = f"{query} {city}"

            params = {
                'query': full_query,
                'language': 'ja',
                'key': self.api_key
            }

            data = get_json(url, params, ttl_sec=60*60*24*7)
                status = data.get('status')
                if status == 'OK':
                    places = data.get('results', [])
                    print(f"      âœ… æ¤œç´¢çµæœ: {len(places)}ä»¶")
                    return places
                elif status == 'OVER_QUERY_LIMIT':
                    print(f"      âŒ APIåˆ¶é™é”æˆ")
                    return 'LIMIT_REACHED'
                else:
                    print(f"      âš ï¸  Status: {status}")

        except Exception as e:
            print(f"      âŒ æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")

        return []

    def extract_permanent_image_url(self, photo_reference):
        """photo_referenceã‹ã‚‰æ°¸ç¶šçš„ãªç›´æ¥URLã‚’å–å¾—"""
        if not photo_reference or not self.api_key:
            return None

        try:
            direct_url = get_photo_direct_url(photo_reference, maxwidth=800, ttl_sec=60*60*24*30)
            return direct_url

        except Exception as e:
            print(f"        ç”»åƒURLå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")

        return None

    def get_fallback_image(self, category_key, name):
        """Unsplashãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”»åƒURLå–å¾—"""
        category_keywords = {
            'parks': 'park nature green',
            'sauna': 'sauna spa relaxation',
            'cafe': 'cafe coffee interior',
            'walking_courses': 'walking path nature trail'
        }

        keyword = category_keywords.get(category_key, 'nature')
        return f"https://source.unsplash.com/800x600/?{keyword}"

    def save_spot(self, place, region, category_key):
        """ã‚¹ãƒãƒƒãƒˆæƒ…å ±ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜"""
        try:
            connection = mysql.connector.connect(**self.mysql_config)
            cursor = connection.cursor()

            # é‡è¤‡ãƒã‚§ãƒƒã‚¯
            place_id = place.get('place_id')
            if place_id:
                cursor.execute("SELECT id FROM spots WHERE place_id = %s", (place_id,))
                if cursor.fetchone():
                    print(f"        âš ï¸  é‡è¤‡ã‚¹ã‚­ãƒƒãƒ—: {place.get('name', 'Unknown')}")
                    cursor.close()
                    connection.close()
                    return False

            # æ°¸ç¶šç”»åƒURLå–å¾—
            permanent_urls = []
            fallback_url = self.get_fallback_image(category_key, place.get('name', ''))

            photos = place.get('photos', [])
            if photos:
                for photo in photos[:3]:  # æœ€å¤§3æš
                    photo_ref = photo.get('photo_reference')
                    if photo_ref:
                        permanent_url = self.extract_permanent_image_url(photo_ref)
                        if permanent_url:
                            permanent_urls.append({
                                'url': permanent_url,
                                'width': photo.get('width'),
                                'height': photo.get('height'),
                                'api_independent': True
                            })
                        time.sleep(0.2)  # APIåˆ¶é™å¯¾ç­–

            # ãƒ‡ãƒ¼ã‚¿æº–å‚™
            geometry = place.get('geometry', {})
            location = geometry.get('location', {})

            spot_data = {
                'place_id': place_id,
                'name': place.get('name'),
                'category': f"relax_{category_key}",
                'address': place.get('formatted_address'),
                'latitude': location.get('lat'),
                'longitude': location.get('lng'),
                'rating': place.get('rating'),
                'user_ratings_total': place.get('user_ratings_total'),
                'price_level': place.get('price_level'),
                'photos': json.dumps(photos) if photos else None,
                'types': json.dumps(place.get('types', [])),
                'vicinity': place.get('vicinity'),
                'plus_code': place.get('plus_code', {}).get('global_code'),
                'region': region,
                'image_urls': json.dumps(permanent_urls) if permanent_urls else None,
                'fallback_image_url': fallback_url
            }

            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æŒ¿å…¥
            insert_query = """
                INSERT INTO spots (
                    place_id, name, category, address, latitude, longitude,
                    rating, user_ratings_total, price_level, photos, types,
                    vicinity, plus_code, region, image_urls, fallback_image_url,
                    created_at, updated_at
                ) VALUES (
                    %(place_id)s, %(name)s, %(category)s, %(address)s, %(latitude)s, %(longitude)s,
                    %(rating)s, %(user_ratings_total)s, %(price_level)s, %(photos)s, %(types)s,
                    %(vicinity)s, %(plus_code)s, %(region)s, %(image_urls)s, %(fallback_image_url)s,
                    NOW(), NOW()
                )
            """

            cursor.execute(insert_query, spot_data)
            connection.commit()

            self.collected_spots += 1
            print(f"        ğŸ’¾ ä¿å­˜å®Œäº†: {place.get('name')}")
            print(f"        ğŸ–¼ï¸  æ°¸ç¶šç”»åƒ: {len(permanent_urls)}ä»¶")

            cursor.close()
            connection.close()
            return True

        except Exception as e:
            print(f"        âŒ ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    def collect_category_region(self, category_key, region_key, target_count=100):
        """ç‰¹å®šã‚«ãƒ†ã‚´ãƒªãƒ¼ãƒ»åœ°åŸŸã®åé›†"""
        category = self.categories[category_key]
        region = self.regions[region_key]

        print(f"\nğŸ¯ åé›†é–‹å§‹: {category['japanese']} Ã— {region['name']}")
        print(f"   ç›®æ¨™: {target_count}ä»¶")

        collected_in_this_session = 0

        for city in region['cities']:
            if collected_in_this_session >= target_count:
                break

            print(f"   ğŸ™ï¸  éƒ½å¸‚: {city}")

            for search_term in category['search_terms']:
                if collected_in_this_session >= target_count:
                    break

                print(f"     ğŸ” æ¤œç´¢: {search_term}")

                places = self.search_places(search_term, region_key, city, category_key)

                if places == 'LIMIT_REACHED':
                    print(f"     âš ï¸  APIåˆ¶é™é”æˆ - å‡¦ç†åœæ­¢")
                    return collected_in_this_session

                if places:
                    for place in places:
                        if collected_in_this_session >= target_count:
                            break

                        success = self.save_spot(place, region_key, category_key)
                        if success:
                            collected_in_this_session += 1

                        time.sleep(0.3)  # APIåˆ¶é™å¯¾ç­–

                time.sleep(1)  # æ¤œç´¢é–“éš”

        print(f"   ğŸ‰ å®Œäº†: {collected_in_this_session}ä»¶åé›†")
        return collected_in_this_session

    def collect_all_massive(self):
        """å…¨ã‚«ãƒ†ã‚´ãƒªãƒ¼ãƒ»å…¨åœ°åŸŸã®å¤§è¦æ¨¡åé›†"""
        print("ğŸš€ å¤§è¦æ¨¡ãƒªãƒ©ãƒƒã‚¯ã‚¹ã‚«ãƒ†ã‚´ãƒªãƒ¼åé›†é–‹å§‹")
        print("ğŸ¯ ç›®æ¨™: 4ã‚«ãƒ†ã‚´ãƒªãƒ¼ Ã— 100ä»¶ Ã— 7åœ°åŸŸ = 2800ä»¶")
        print("ğŸ–¼ï¸  æ°¸ç¶šç”»åƒURLå¯¾å¿œæ¸ˆã¿\n")

        total_collected = 0

        for category_key, category in self.categories.items():
            print(f"\nğŸ“‚ ã‚«ãƒ†ã‚´ãƒªãƒ¼: {category['japanese']} ({category_key})")
            category_total = 0

            for region_key, region in self.regions.items():
                collected = self.collect_category_region(category_key, region_key, 100)
                category_total += collected
                total_collected += collected

                print(f"   ğŸ“Š {region['name']}: {collected}ä»¶")
                print(f"   ğŸ”§ APIä½¿ç”¨: {self.api_usage}å›")

                # å¤§é‡å‡¦ç†ã®ä¼‘æ†©
                if self.api_usage % 50 == 0:
                    print(f"   ğŸ˜´ APIåˆ¶é™å¯¾ç­–ä¼‘æ†©ï¼ˆ10ç§’ï¼‰...")
                    time.sleep(10)

            print(f"ğŸ¯ {category['japanese']} å®Œäº†: {category_total}ä»¶")

        print(f"\nğŸ‰ å¤§è¦æ¨¡åé›†å®Œäº†!")
        print(f"   ğŸ“Š ç·åé›†æ•°: {total_collected}ä»¶")
        print(f"   ğŸ”§ APIä½¿ç”¨: {self.api_usage}å›")
        print(f"   ğŸ–¼ï¸  å…¨ã¦æ°¸ç¶šç”»åƒURLå¯¾å¿œæ¸ˆã¿")

def main():
    print("ğŸ—ï¸  å¤§è¦æ¨¡ãƒªãƒ©ãƒƒã‚¯ã‚¹ã‚«ãƒ†ã‚´ãƒªãƒ¼åé›†ã‚·ã‚¹ãƒ†ãƒ ")
    print("ğŸ’« APIã‚­ãƒ¼ä¾å­˜ãªã—æ°¸ç¶šç”»åƒã‚·ã‚¹ãƒ†ãƒ ")
    print("âš¡ 2800ä»¶ãƒ‡ãƒ¼ã‚¿åé›†\n")

    collector = MassiveRelaxCollector()
    collector.collect_all_massive()

if __name__ == "__main__":
    main()
