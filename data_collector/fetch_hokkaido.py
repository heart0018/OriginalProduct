#!/usr/bin/env python3
"""
ÂåóÊµ∑ÈÅìÂ§ö„Ç´„ÉÜ„Ç¥„É™„Çπ„Éù„ÉÉ„ÉàËá™ÂãïÂèñÂæó„Çπ„ÇØ„É™„Éó„Éà
Google Places API„Çí‰ΩøÁî®„Åó„Å¶ÂåóÊµ∑ÈÅì„ÅÆÊ∏©Ê≥â„ÉªÂÖ¨Âúí„Éª„Çµ„Ç¶„Éä„Éª„Ç´„Éï„Çß„Éá„Éº„Çø„ÇíÂèñÂæó„Åó„ÄÅMySQL„Å´‰øùÂ≠ò„Åô„Çã
(Èñ¢Êù±Áâà„Å®ÂÖ®„ÅèÂêå„Åò‰ªïÊßò / ÂùáÁ≠âÈÖçÂàÜ=Âçò‰∏ÄÁúå„Å™„ÅÆ„Åß„Åù„ÅÆ„Åæ„Åæ / „Éà„ÉÉ„Éó„Ç¢„ÉÉ„Éó / ÂÜçÈÖçÂàÜ / „Çµ„Ç¶„ÉäÁ¨¨‰∫å„Éï„Çß„Éº„Ç∫ ÂØæÂøú)
"""

import os
import sys
import requests
import mysql.connector
from mysql.connector import Error
from dotenv import load_dotenv
from typing import List, Dict, Optional
import time

# .envË™≠„ÅøËæº„Åø
load_dotenv()

class HokkaidoDataCollector:
    def __init__(self):
        self.google_api_key = os.getenv('GOOGLE_API_KEY')
        self.mysql_config = {
            'host': 'localhost',
            'user': 'Haruto',
            'password': os.getenv('MYSQL_PASSWORD'),
            'database': 'swipe_app_development',
            'charset': 'utf8mb4'
        }
        self.places_api_base = 'https://maps.googleapis.com/maps/api/place'
        self.text_search_url = f"{self.places_api_base}/textsearch/json"
        self.place_details_url = f"{self.places_api_base}/details/json"

        # ÂåóÊµ∑ÈÅì„ÅÆ„ÅøÔºàÂùáÁ≠âÈÖçÂàÜ„É≠„Ç∏„ÉÉ„ÇØ„ÅØ„Åù„ÅÆ„Åæ„ÅæÂà©Áî®Ôºâ
        self.prefectures = ['ÂåóÊµ∑ÈÅì']

        self.search_categories = {
            'relax_onsen': {
                'base_terms': [
                    'Ê∏©Ê≥â','Èä≠ÊπØ','„Çπ„Éº„Éë„ÉºÈä≠ÊπØ','Â§©ÁÑ∂Ê∏©Ê≥â','Êó•Â∏∞„ÇäÊ∏©Ê≥â',
                    'Ê∏©Ê≥âÊñΩË®≠','ÂÖ•Êµ¥ÊñΩË®≠','Â≤©Áõ§Êµ¥'
                ],
                'queries': self._generate_regional_queries([
                    'Ê∏©Ê≥â','Èä≠ÊπØ','„Çπ„Éº„Éë„ÉºÈä≠ÊπØ','Â§©ÁÑ∂Ê∏©Ê≥â','Êó•Â∏∞„ÇäÊ∏©Ê≥â',
                    'Ê∏©Ê≥âÊñΩË®≠','ÂÖ•Êµ¥ÊñΩË®≠','Â≤©Áõ§Êµ¥'
                ]),
                'keywords': ['Ê∏©Ê≥â','Èä≠ÊπØ','„Çπ„Éë','spa','hot spring','bath house','ÂÖ•Êµ¥','Â≤©Áõ§Êµ¥'],
                'exclude_types': ['lodging','hotel'],
                'target_count': 100
            },
            'active_park': {
                'base_terms': [
                    'ÂÖ¨Âúí','ÈÉΩÂ∏ÇÂÖ¨Âúí','Á∑ëÂú∞','ÈÅãÂãïÂÖ¨Âúí','ÈÅìÁ´ãÂÖ¨Âúí',
                    'Ëá™ÁÑ∂ÂÖ¨Âúí','Ê£ÆÊûóÂÖ¨Âúí','Á∑èÂêàÂÖ¨Âúí','Êï£Ê≠©„Ç≥„Éº„Çπ'
                ],
                'queries': self._generate_regional_queries([
                    'ÂÖ¨Âúí','ÈÉΩÂ∏ÇÂÖ¨Âúí','Á∑ëÂú∞','ÈÅãÂãïÂÖ¨Âúí','ÈÅìÁ´ãÂÖ¨Âúí',
                    'Ëá™ÁÑ∂ÂÖ¨Âúí','Ê£ÆÊûóÂÖ¨Âúí','Á∑èÂêàÂÖ¨Âúí','Êï£Ê≠©„Ç≥„Éº„Çπ'
                ]),
                'keywords': ['ÂÖ¨Âúí','park','Á∑ëÂú∞','ÈÅãÂãïÂ†¥','„Çπ„Éù„Éº„ÉÑ','Â∫ÉÂ†¥','Êï£Ê≠©','ÈÅäÊ≠©ÈÅì'],
                'exclude_types': ['lodging','hotel'],
                'target_count': 100
            },
            'active_sauna': {
                'base_terms': [
                    '„Çµ„Ç¶„Éä','„Çµ„Ç¶„ÉäÊñΩË®≠','ÂÄãÂÆ§„Çµ„Ç¶„Éä','„Éï„Ç£„É≥„É©„É≥„Éâ„Çµ„Ç¶„Éä',
                    '„É≠„Ç¶„É™„É•','„Çµ„Ç¶„Éä&„Çπ„Éë','Â≤©Áõ§Êµ¥','„ÉÜ„É≥„Éà„Çµ„Ç¶„Éä',
                    'Â§ñÊ∞óÊµ¥','Ê∞¥È¢®ÂëÇ','„Çµ„Ç¶„Éä„É©„Ç¶„É≥„Ç∏','„ÇµÊ¥ª','È´òÊ∏©„Çµ„Ç¶„Éä',
                    '‰ΩéÊ∏©„Çµ„Ç¶„Éä','„Å®„Å®„ÅÆ„ÅÑ','Êï¥„ÅÑ','Áô∫Ê±ó','„Çµ„Ç¶„Éä„Ç´„Éï„Çß'
                ],
                'queries': self._generate_regional_queries([
                    '„Çµ„Ç¶„Éä','„Çµ„Ç¶„ÉäÊñΩË®≠','ÂÄãÂÆ§„Çµ„Ç¶„Éä','„Éï„Ç£„É≥„É©„É≥„Éâ„Çµ„Ç¶„Éä',
                    '„É≠„Ç¶„É™„É•','„Çµ„Ç¶„Éä&„Çπ„Éë','Â≤©Áõ§Êµ¥','„ÉÜ„É≥„Éà„Çµ„Ç¶„Éä',
                    'Â§ñÊ∞óÊµ¥','Ê∞¥È¢®ÂëÇ','„Çµ„Ç¶„Éä„É©„Ç¶„É≥„Ç∏','„ÇµÊ¥ª','È´òÊ∏©„Çµ„Ç¶„Éä',
                    '‰ΩéÊ∏©„Çµ„Ç¶„Éä','„Å®„Å®„ÅÆ„ÅÑ','Êï¥„ÅÑ','Áô∫Ê±ó','„Çµ„Ç¶„Éä„Ç´„Éï„Çß'
                ]),
                'keywords': ['„Çµ„Ç¶„Éä','sauna','„É≠„Ç¶„É™„É•','Â≤©Áõ§Êµ¥','„ÉÜ„É≥„Éà','Â§ñÊ∞óÊµ¥','Ê∞¥È¢®ÂëÇ','Êï¥','„Å®„Å®„ÅÆ','Áô∫Ê±ó','„ÇµÊ¥ª'],
                'exclude_types': ['lodging','hotel'],
                'target_count': 100
            },
            'relax_cafe': {
                'base_terms': [
                    '„Ç´„Éï„Çß','„Ç≥„Éº„Éí„Éº„Ç∑„Éß„ÉÉ„Éó','ÂãïÁâ©„Ç´„Éï„Çß','Áå´„Ç´„Éï„Çß',
                    '„Éâ„ÉÉ„Ç∞„Ç´„Éï„Çß','Âè§Ê∞ëÂÆ∂„Ç´„Éï„Çß','Èö†„ÇåÂÆ∂„Ç´„Éï„Çß','Âñ´Ëå∂Â∫ó'
                ],
                'queries': self._generate_regional_queries([
                    '„Ç´„Éï„Çß','„Ç≥„Éº„Éí„Éº„Ç∑„Éß„ÉÉ„Éó','ÂãïÁâ©„Ç´„Éï„Çß','Áå´„Ç´„Éï„Çß',
                    '„Éâ„ÉÉ„Ç∞„Ç´„Éï„Çß','Âè§Ê∞ëÂÆ∂„Ç´„Éï„Çß','Èö†„ÇåÂÆ∂„Ç´„Éï„Çß','Âñ´Ëå∂Â∫ó'
                ]),
                'keywords': ['„Ç´„Éï„Çß','cafe','coffee','„Ç≥„Éº„Éí„Éº','Âñ´Ëå∂','ÂãïÁâ©','Áå´','Áä¨'],
                'exclude_types': ['lodging','hotel'],
                'target_count': 100
            }
        }
        self.total_target_count = 400

    def _generate_regional_queries(self, base_terms: List[str]) -> List[str]:
        queries = []
        for pref in self.prefectures:
            for term in base_terms:
                queries.append(f"{term} {pref}")
        for term in base_terms:
            queries.extend([
                f"{term} ÂåóÊµ∑ÈÅì",
                f"ÂåóÊµ∑ÈÅì {term}"
            ])
        return queries

    def validate_config(self):
        if not self.google_api_key:
            raise ValueError('GOOGLE_API_KEY Êú™Ë®≠ÂÆö')
        if not self.mysql_config['password']:
            raise ValueError('MYSQL_PASSWORD Êú™Ë®≠ÂÆö')
        print('‚úÖ Ë®≠ÂÆöOK')

    def search_places(self, query: str) -> List[Dict]:
        params = {
            'query': query,
            'key': self.google_api_key,
            'language': 'ja',
            'region': 'jp'
        }
        try:
            print(f"üîç Ê§úÁ¥¢: {query}")
            r = requests.get(self.text_search_url, params=params, timeout=20)
            r.raise_for_status()
            data = r.json()
            if data.get('status') != 'OK':
                if data.get('status') != 'ZERO_RESULTS':
                    print(f"‚ö†Ô∏è Ê§úÁ¥¢„Ç®„É©„Éº {data.get('status')}")
                return []
            results = data.get('results', [])
            filtered = []
            for res in results:
                addr = res.get('formatted_address','')
                if any(pref in addr for pref in self.prefectures):
                    filtered.append(res)
            print(f"üìç ÂåóÊµ∑ÈÅìÂÜÖÂÄôË£ú {len(filtered)}‰ª∂")
            return filtered
        except requests.RequestException as e:
            print(f"‚ùå Ê§úÁ¥¢Â§±Êïó: {e}")
            return []

    def get_place_details(self, place_id: str) -> Optional[Dict]:
        params = {
            'place_id': place_id,
            'key': self.google_api_key,
            'language': 'ja',
            'fields': 'name,formatted_address,rating,user_ratings_total,photos,url,types,geometry,opening_hours,reviews'
        }
        try:
            r = requests.get(self.place_details_url, params=params, timeout=20)
            r.raise_for_status()
            data = r.json()
            if data.get('status') != 'OK':
                print(f"‚ö†Ô∏è Ë©≥Á¥∞NG {data.get('status')}")
                return None
            return data.get('result')
        except requests.RequestException as e:
            print(f"‚ùå Ë©≥Á¥∞ÂèñÂæóÂ§±Êïó: {e}")
            return None

    def get_photo_url(self, photo_reference: str, max_width: int = 200) -> str:
        return f"{self.places_api_base}/photo?maxwidth={max_width}&photo_reference={photo_reference}&key={self.google_api_key}"

    def validate_place_id(self, place_id: str) -> bool:
        if not place_id:
            return False
        params = {'place_id': place_id,'key': self.google_api_key,'fields': 'place_id'}
        try:
            r = requests.get(self.place_details_url, params=params, timeout=10)
            r.raise_for_status()
            d = r.json()
            ok = d.get('status') == 'OK'
            print(f"  {'‚úÖ' if ok else '‚ùå'} place_idÊ§úË®º {place_id[:20]}...")
            return ok
        except requests.RequestException:
            print('  ‚ùå place_idÊ§úË®ºÈÄö‰ø°Â§±Êïó')
            return False

    def is_japanese_text(self, text: str) -> bool:
        if not text:
            return False
        stripped = text.replace(' ','').replace('\n','')
        if not stripped:
            return False
        jp = 0
        for ch in stripped:
            if ('\u3040' <= ch <= '\u309F') or ('\u30A0' <= ch <= '\u30FF') or ('\u4E00' <= ch <= '\u9FAF'):
                jp += 1
        return jp/len(stripped) >= 0.3

    def extract_japanese_reviews(self, reviews: List[Dict], max_count: int = 10) -> List[Dict]:
        if not reviews:
            return []
        jr = []
        for rv in reviews:
            txt = rv.get('text','')
            if self.is_japanese_text(txt):
                jr.append({
                    'text': txt,
                    'rating': rv.get('rating',0),
                    'time': rv.get('time',0),
                    'author_name': rv.get('author_name',''),
                    'relative_time_description': rv.get('relative_time_description','')
                })
        jr.sort(key=lambda x: x['time'], reverse=True)
        return jr[:max_count]

    def filter_places_by_category(self, places: List[Dict], category: str) -> List[Dict]:
        if category not in self.search_categories:
            return []
        cfg = self.search_categories[category]
        keywords = cfg['keywords']
        exclude = cfg['exclude_types']
        out = []
        for p in places:
            name = (p.get('name','') or '').lower()
            types = p.get('types',[]) or []
            has_kw = any(k in name for k in keywords)
            if not has_kw and category == 'active_sauna':
                sauna_frag = any(f in name for f in ['„Çµ„Ç¶„Éä','Êï¥','„Å®„Å®„ÅÆ'])
                type_hint = any(t in types for t in ['spa','gym','health','establishment'])
                if sauna_frag and type_hint:
                    has_kw = True
            if not has_kw:
                continue
            if any(ex in types for ex in exclude):
                continue
            out.append(p)
        return out

    def format_place_data(self, place: Dict, category: str, details: Optional[Dict]=None) -> Dict:
        src = details or place
        name = src.get('name', place.get('name',''))[:128]
        address = src.get('formatted_address', place.get('formatted_address',''))[:128]
        rating = float(src.get('rating', place.get('rating',0.0)) or 0.0)
        review_count = int(src.get('user_ratings_total', place.get('user_ratings_total',0)) or 0)
        latitude = longitude = None
        geom = src.get('geometry',{})
        if 'location' in geom:
            latitude = geom['location'].get('lat')
            longitude = geom['location'].get('lng')
            print(f"  üìç ({latitude},{longitude})")
        image_url = None
        photos = src.get('photos',[]) or []
        if photos:
            ref = photos[0].get('photo_reference')
            if ref:
                url = self.get_photo_url(ref, max_width=200)
                if len(url) <= 1000:
                    image_url = url
                    print(f"  üì∏ ÁîªÂÉèOK len={len(url)}")
        external_link = src.get('url','')
        pid = place.get('place_id')
        if not external_link and pid:
            external_link = f"https://maps.google.com/?place_id={pid}"
        if len(external_link) > 256 and pid:
            external_link = f"https://maps.google.com/?place_id={pid}"[:256]
        reviews = []
        if details and 'reviews' in details:
            reviews = self.extract_japanese_reviews(details['reviews'], max_count=10)
            print(f"  üí¨ JP„É¨„Éì„É•„Éº {len(reviews)}‰ª∂")
        return {
            'genre': category,
            'title': name,
            'rating': rating,
            'review_count': review_count,
            'image_url': image_url,
            'external_link': external_link,
            'region': 'ÂåóÊµ∑ÈÅì',
            'address': address,
            'latitude': latitude,
            'longitude': longitude,
            'place_id': pid,
            'reviews': reviews
        }

    def connect_database(self):
        try:
            conn = mysql.connector.connect(**self.mysql_config)
            if conn.is_connected():
                print('‚úÖ DBÊé•Á∂ö')
                return conn
        except Error as e:
            print(f'‚ùå DBÊé•Á∂öÂ§±Êïó: {e}')
        return None

    def save_to_database(self, rows: List[Dict]):
        conn = self.connect_database()
        if not conn:
            return False
        try:
            cur = conn.cursor()
            check_q = 'SELECT id FROM cards WHERE place_id=%s'
            insert_card = (
                'INSERT INTO cards (genre,title,rating,review_count,image_url,external_link,region,address,latitude,longitude,place_id,created_at,updated_at) '
                'VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,NOW(),NOW())'
            )
            insert_rev = 'INSERT INTO review_comments (comment,card_id,created_at,updated_at) VALUES (%s,%s,NOW(),NOW())'
            ins = dup = rev_sum = 0
            for r in rows:
                pid = r.get('place_id')
                if not pid:
                    dup += 1
                    continue
                cur.execute(check_q,(pid,))
                if cur.fetchone():
                    dup += 1
                    continue
                cur.execute(insert_card,(
                    r['genre'],r['title'],r['rating'],r['review_count'],r['image_url'],r['external_link'],
                    r['region'],r['address'],r['latitude'],r['longitude'],r['place_id']
                ))
                card_id = cur.lastrowid
                added_rev = 0
                for rev in r.get('reviews',[]):
                    txt = rev['text']
                    if len(txt) > 1000:
                        txt = txt[:997]+'...'
                    cur.execute(insert_rev,(txt,card_id))
                    added_rev += 1
                rev_sum += added_rev
                ins += 1
                print(f"‚úÖ ‰øùÂ≠ò: {r['title']} („É¨„Éì„É•„Éº{added_rev})")
            conn.commit()
            print(f"\nüìä ÊåøÂÖ• {ins} / ÈáçË§á {dup}  „É¨„Éì„É•„Éº {rev_sum}")
            return True
        except Error as e:
            print(f'‚ùå DB„Ç®„É©„Éº: {e}')
            conn.rollback()
            return False
        finally:
            if conn.is_connected():
                cur.close(); conn.close(); print('‚úÖ DBÂàáÊñ≠')

    def _load_existing_place_ids(self) -> set:
        conn = self.connect_database()
        ids = set()
        if not conn:
            return ids
        try:
            cur = conn.cursor()
            cur.execute('SELECT place_id FROM cards WHERE place_id IS NOT NULL')
            for (pid,) in cur.fetchall():
                if pid: ids.add(pid)
        finally:
            if conn.is_connected():
                cur.close(); conn.close()
        return ids

    def _get_existing_counts(self, category: str):
        conn = self.connect_database()
        total = 0
        pref_counts = {p:0 for p in self.prefectures}
        if not conn:
            return total, pref_counts
        try:
            cur = conn.cursor()
            cur.execute("SELECT COUNT(*) FROM cards WHERE genre=%s AND region='ÂåóÊµ∑ÈÅì'", (category,))
            total = cur.fetchone()[0]
            cur.execute("SELECT address FROM cards WHERE genre=%s AND region='ÂåóÊµ∑ÈÅì'", (category,))
            for (addr,) in cur.fetchall():
                if not addr:
                    continue
                if 'ÂåóÊµ∑ÈÅì' in addr:
                    pref_counts['ÂåóÊµ∑ÈÅì'] += 1
        finally:
            if conn.is_connected():
                cur.close(); conn.close()
        return total, pref_counts

    def collect_data(self, category: Optional[str]=None):
        print('üöÄ ÂåóÊµ∑ÈÅì Â§ö„Ç´„ÉÜ„Ç¥„É™ÂèéÈõÜÈñãÂßã')
        self.validate_config()
        ZERO_GAIN_LIMIT = 5
        REALLOC_ALLOW_DIFF = 1
        EXTRA_ONSEN = ['ÂÅ•Â∫∑„É©„É≥„Éâ','Ê∏©Êµ¥','Ê∏©Êµ¥ÊñΩË®≠','„Çπ„Éë„É™„Çæ„Éº„Éà','„É™„Çæ„Éº„ÉàÊ∏©Ê≥â','Ê∫êÊ≥â„Åã„ÅëÊµÅ„Åó','Êó•Â∏∞„ÇäÂÖ•Êµ¥','Ê∏©Ê≥â„Çª„É≥„Çø„Éº']
        SAUNA_EXPAND = ['„ÉÜ„É≥„Éà„Çµ„Ç¶„Éä','Â§ñÊ∞óÊµ¥','Ê∞¥È¢®ÂëÇ','„Å®„Å®„ÅÆ„ÅÑ','Êï¥„ÅÑ','È´òÊ∏©„Çµ„Ç¶„Éä','‰ΩéÊ∏©„Çµ„Ç¶„Éä','„Çµ„Ç¶„Éä„É©„Ç¶„É≥„Ç∏','„ÇµÊ¥ª','Áô∫Ê±ó']
        categories = [category] if category else list(self.search_categories.keys())
        all_rows = []
        for cat in categories:
            if cat not in self.search_categories:
                print(f'‚ö†Ô∏è Êú™Áü•„Ç´„ÉÜ„Ç¥„É™ {cat}')
                continue
            cfg = self.search_categories[cat]
            full_target = cfg['target_count']
            existing_total, existing_pref = self._get_existing_counts(cat)
            existing_ids = self._load_existing_place_ids()
            if existing_total >= full_target:
                print(f"‚úÖ {cat} Êó¢„Å´ {full_target}‰ª∂Âà∞ÈÅî „Çπ„Ç≠„ÉÉ„Éó")
                continue
            remaining = full_target - existing_total
            print(f"\nüîç {cat}: Êó¢Â≠ò {existing_total}/{full_target} ‚Üí ËøΩÂä† {remaining}")
            # Âçò‰∏ÄÁúå„Å™„ÅÆ„Åß quota=remaining
            quotas = {'ÂåóÊµ∑ÈÅì': remaining}
            print(f"üßÆ ËøΩÂä†„ÇØ„Ç©„Éº„Çø: {quotas}")
            query_map = {'ÂåóÊµ∑ÈÅì':[f"{t} ÂåóÊµ∑ÈÅì" for t in cfg['base_terms']]}
            collected = {}
            counts = {'ÂåóÊµ∑ÈÅì':0}
            exhausted = {'ÂåóÊµ∑ÈÅì': quotas['ÂåóÊµ∑ÈÅì']==0}
            zero_streak = {'ÂåóÊµ∑ÈÅì':0}
            rounds=0
            target = remaining
            while sum(counts.values()) < target and not all(exhausted.values()):
                rounds += 1
                pref = 'ÂåóÊµ∑ÈÅì'
                if counts[pref] >= quotas[pref] or exhausted[pref]:
                    break
                if not query_map[pref]:
                    exhausted[pref] = True
                    break
                q = query_map[pref].pop(0)
                places = self.search_places(q)
                filtered = self.filter_places_by_category(places, cat)
                added=0
                for p in filtered:
                    if counts[pref] >= quotas[pref]:
                        break
                    pid = p.get('place_id')
                    addr = p.get('formatted_address','')
                    if not pid or pid in collected or pid in existing_ids:
                        continue
                    if 'ÂåóÊµ∑ÈÅì' not in addr:
                        continue
                    collected[pid]=p
                    counts[pref]+=1
                    added+=1
                if added==0:
                    zero_streak[pref]+=1
                else:
                    zero_streak[pref]=0
                print(f"üîÅ R{rounds} {pref} {q}: +{added} ({counts[pref]}/{quotas[pref]}) streak={zero_streak[pref]}")
                time.sleep(0.6)
                if zero_streak[pref] >= ZERO_GAIN_LIMIT and counts[pref] < quotas[pref]:
                    print(f"  ‚õî ÈÄ£Á∂ö0‰ª∂{ZERO_GAIN_LIMIT}Âõû Êâì„Å°Âàá„Çä")
                    exhausted[pref]=True
                if counts[pref] < quotas[pref] and not query_map[pref]:
                    extra_terms = cfg['keywords'][:3]
                    if cat=='relax_onsen':
                        extra_terms = list(dict.fromkeys(extra_terms + EXTRA_ONSEN))
                    if cat=='active_sauna':
                        extra_terms = list(dict.fromkeys(extra_terms + SAUNA_EXPAND))
                    query_map[pref] = [f"{t} ÂåóÊµ∑ÈÅì" for t in extra_terms]
            deficit = target - sum(counts.values())
            if cat=='active_sauna' and deficit>0:
                print(f"üî• active_sauna Á¨¨‰∫å„Éï„Çß„Éº„Ç∫ ‰∏çË∂≥ {deficit}")
                SECOND = ['„Çª„É´„Éï„É≠„Ç¶„É™„É•','„Ç¢„Ç¶„Éà„Éâ„Ç¢„Çµ„Ç¶„Éä','Ëñ™„Çµ„Ç¶„Éä','Ë≤∏Âàá„Çµ„Ç¶„Éä','„Éó„É©„Ç§„Éô„Éº„Éà„Çµ„Ç¶„Éä','„Çµ„Ç¶„Éä„ÉÜ„É≥„Éà','Êú¨Ê†º„Çµ„Ç¶„Éä','„Çµ„Ç¶„Éä Â∞èË¶èÊ®°','„Çµ„Ç¶„Éä „Çπ„Éë','Êï¥„ÅÑ„Çπ„Éö„Éº„Çπ','ÂÅ•Â∫∑„É©„É≥„Éâ „Çµ„Ç¶„Éä','„Çπ„Éë „Çµ„Ç¶„Éä','„É™„É©„ÇØ„Çº„Éº„Ç∑„Éß„É≥ „Çµ„Ç¶„Éä']
                r2=0
                while deficit>0 and r2<40:
                    r2+=1
                    term = SECOND[r2 % len(SECOND)]
                    q = f"{term} ÂåóÊµ∑ÈÅì"
                    places = self.search_places(q)
                    for p in places:
                        if deficit<=0:
                            break
                        pid = p.get('place_id')
                        if not pid or pid in collected or pid in existing_ids:
                            continue
                        addr = p.get('formatted_address','')
                        if 'ÂåóÊµ∑ÈÅì' not in addr:
                            continue
                        name_low = (p.get('name','') or '').lower()
                        types = p.get('types',[]) or []
                        if not (any(k in name_low for k in ['„Çµ„Ç¶„Éä','Êï¥','„Å®„Å®„ÅÆ','„Çπ„Éë','ÂÅ•Â∫∑','Â≤©Áõ§']) or any(t in types for t in ['spa','health','gym','bath','establishment'])):
                            continue
                        collected[pid]=p
                        counts['ÂåóÊµ∑ÈÅì']+=1
                        deficit-=1
                    print(f"  üîç Á¨¨‰∫åR{r2} {q} ÈÄ≤Êçó {counts['ÂåóÊµ∑ÈÅì']}/{quotas['ÂåóÊµ∑ÈÅì']} ÊÆã deficit {deficit}")
                    time.sleep(0.5)
                    if r2>60: break
                if deficit>0:
                    print(f"‚ö†Ô∏è Á¨¨‰∫å„Éï„Çß„Éº„Ç∫Âæå„ÇÇ‰∏çË∂≥ {deficit}")
                else:
                    print('‚úÖ Á¨¨‰∫å„Éï„Çß„Éº„Ç∫ÂÖÖË∂≥')
            # Ë©≥Á¥∞ÂèñÂæó
            target_fetch = min(counts['ÂåóÊµ∑ÈÅì'], target)
            print(f"üì¶ {cat} Ë©≥Á¥∞ÂèñÂæó {target_fetch}‰ª∂")
            cat_rows=[]
            i=0
            for pid, place in list(collected.items()):
                if i>=target_fetch: break
                if pid in existing_ids: continue
                print(f"  ({i+1}/{target_fetch}) {place.get('name')} Ë©≥Á¥∞")
                if not self.validate_place_id(pid):
                    continue
                details = self.get_place_details(pid)
                time.sleep(0.7)
                row = self.format_place_data(place, cat, details)
                cat_rows.append(row)
                i+=1
            print(f"‚úÖ {cat} ËøΩÂä†Ê∫ñÂÇô {len(cat_rows)}‰ª∂")
            all_rows.extend(cat_rows)
        print(f"\nüíæ ‰øùÂ≠òÂØæË±° {len(all_rows)}‰ª∂")
        if all_rows:
            self.save_to_database(all_rows)
        else:
            print('‚ÑπÔ∏è ËøΩÂä†„Å™„Åó')
        print('üéâ Âá¶ÁêÜÂÆå‰∫Ü')
        return True

def main():
    try:
        collector = HokkaidoDataCollector()
        cat = None
        if '--category' in sys.argv:
            idx = sys.argv.index('--category')
            if idx+1 < len(sys.argv):
                cat = sys.argv[idx+1]
        collector.collect_data(category=cat)
    except KeyboardInterrupt:
        print('\n‚ö†Ô∏è ‰∏≠Êñ≠')
    except Exception as e:
        print(f"\n‚ùå ‰∫àÊúü„Åõ„Å¨„Ç®„É©„Éº: {e}")
        import traceback; traceback.print_exc()

if __name__ == '__main__':
    main()
